{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f15e146-f81d-49f6-adb0-d3f5b64039d5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f84b85-bb9c-4bff-b2bb-2da8d10f6517",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('./4sec', lines=True)\n",
    "\n",
    "msg_rate = 500\n",
    "n_workers = 1\n",
    "n_partitions = 8\n",
    "\n",
    "filename = f'./results/workers_{n_workers}_rate_{msg_rate}_partitions_{n_partitions}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef8c2285-f106-47cc-aed7-a24fb184abe8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = '4_sec.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff96c23c-2d74-47b3-819f-c2e040c6e495",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stream_data = df[df['Event']=='org.apache.spark.sql.streaming.StreamingQueryListener$QueryProgressEvent']\n",
    "\n",
    "batchId = []\n",
    "batchDuration = []\n",
    "numInputRows = []\n",
    "inputRowsPerSecond = []\n",
    "processedRowsPerSecond = []\n",
    "\n",
    "for el in stream_data['progress']:\n",
    "    batchId.append(el['batchId'])\n",
    "    batchDuration.append(el['batchDuration'])\n",
    "    \n",
    "    nested = el['sources'][0]\n",
    "    \n",
    "    numInputRows.append(nested['numInputRows'])\n",
    "    inputRowsPerSecond.append(nested['inputRowsPerSecond'])\n",
    "    processedRowsPerSecond.append(nested['processedRowsPerSecond'])\n",
    "    \n",
    "metrics = {\n",
    "    'batchId': batchId,\n",
    "    'batchDuration': batchDuration,\n",
    "    'numInputRows': numInputRows,\n",
    "    'inputRowsPerSecond': inputRowsPerSecond,\n",
    "    'processedRowsPerSecond': processedRowsPerSecond\n",
    "}\n",
    "\n",
    "with open(filename, 'w') as fp:\n",
    "    json.dump(metrics, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9b84e-fea9-4e73-9f76-dd60c5fcf37f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NNDL-torch]",
   "language": "python",
   "name": "conda-env-NNDL-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}